{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "#Dwave imports\n",
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.system.composites import EmbeddingComposite\n",
    "import dimod\n",
    "from __future__ import print_function\n",
    "\n",
    "import dimod\n",
    "import math\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "from dimod.generators.constraints import combinations\n",
    "from hybrid.reference import KerberosSampler\n",
    "\n",
    "#Impots for QUBO problem\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import itertools as it\n",
    "from itertools import product\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import json\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to find the set of indicies that are next to vertex p. Verticies are labeled numerically from 0 to N^2 - 1\n",
    "# We note that the index can be encoded as a tuple via p = px*n+py, hence py = p mod n and px = (i - iy)/n\n",
    "\n",
    "def next_to(p,n,T):\n",
    "    if T == 'Default':\n",
    "        py = int(p % n) # the y coordinate (y in {0,...,n-1})\n",
    "        px = int((p - py)/n) # the x coordinate (x in {0,...,n-1})\n",
    "        # print((px,py))\n",
    "        adjacent_set = []\n",
    "        if px + 1 < n and px + 1 >= 0:\n",
    "            adjacent_set.append((px + 1, py))\n",
    "        if px - 1 < n and px - 1 >= 0:\n",
    "            adjacent_set.append((px - 1, py))\n",
    "        if py + 1 < n and py + 1 >= 0:\n",
    "            adjacent_set.append((px, py + 1))\n",
    "        if py - 1 < n and py - 1 >= 0:\n",
    "            adjacent_set.append((px, py - 1)) \n",
    "        tensors = []\n",
    "        neighbours = []\n",
    "        for x,y in adjacent_set:\n",
    "            tensors.append(f'G_{x*n + y}')\n",
    "            neighbours.append(x*n + y)\n",
    "        return neighbours\n",
    "    \n",
    "    elif T == 'Periodic':\n",
    "        py = int(p % n) # the y coordinate (y in {0,...,n-1})\n",
    "        px = int((p - py)/n) # the x coordinate (x in {0,...,n-1})\n",
    "        # print((px,py))\n",
    "        adjacent_set = []\n",
    "        adjacent_set.append(((px + 1) % n, py))\n",
    "        adjacent_set.append(((px - 1) % n, py)) \n",
    "        adjacent_set.append((px, (py + 1) % n))\n",
    "        adjacent_set.append((px, (py - 1) % n)) \n",
    "        tensors = []\n",
    "        neighbours = []\n",
    "        # print(f'G_{p}')\n",
    "        for x,y in adjacent_set:\n",
    "            # print((px,py),f'G_{x*n + y}')\n",
    "            tensors.append(f'G_{x*n + y}')\n",
    "            neighbours.append(x*n + y)\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "\n",
    "    elif T == 'X Shift':\n",
    "        shift = 1\n",
    "        py = int(p % n) # the y coordinate (y in {0,...,n-1})\n",
    "        px = int((p - py)/n) # the x coordinate (x in {0,...,n-1})\n",
    "        # print((px,py))\n",
    "        adjacent_set = []\n",
    "        \n",
    "\n",
    "        #Bulk\n",
    "        if px not in [0,n-1]:\n",
    "            adjacent_set.append(((px + 1) % n, py))\n",
    "            adjacent_set.append(((px - 1) % n, py)) \n",
    "            adjacent_set.append((px, (py + 1) % n))\n",
    "            adjacent_set.append((px, (py - 1) % n)) \n",
    "            # print('Bulk point: ',adjacent_set)\n",
    "        #x lower boundary\n",
    "        elif px == 0:\n",
    "            adjacent_set.append(((px + 1) % n, py))\n",
    "            adjacent_set.append(((px - 1) % n, (py - shift) % n)) \n",
    "            adjacent_set.append((px, (py + 1) % n))\n",
    "            adjacent_set.append((px, (py - 1) % n))\n",
    "            # print('lower x point: ', adjacent_set)\n",
    "        #x upper boundary\n",
    "        elif px == n-1:\n",
    "            adjacent_set.append(((px + 1) % n, (py + shift) % n))\n",
    "            adjacent_set.append(((px - 1) % n, py % n)) \n",
    "            adjacent_set.append((px, (py + 1) % n))\n",
    "            adjacent_set.append((px, (py - 1) % n))\n",
    "            # print('upper x point: ', adjacent_set)\n",
    "        tensors = []\n",
    "        neighbours = []\n",
    "        # print(f'G_{p}')\n",
    "        for x,y in adjacent_set:\n",
    "            # print((px,py),f'G_{x*n + y}')\n",
    "            tensors.append(f'G_{x*n + y}')\n",
    "            neighbours.append(x*n + y)\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "# Convert to coordiante form\n",
    "def coords(p,n):\n",
    "    p = int(p)\n",
    "    py = int(p % n) # the y coordinate (y in {0,...,n-1})\n",
    "    px = int((p - py)/n) # the x coordinate (x in {0,...,n-1})\n",
    "    return (px,py)\n",
    "\n",
    "# Get adjacent Edges for each point\n",
    "def edge_set(p,n):\n",
    "    neighbours = next_to(p,n, T = BC)\n",
    "    edge_set = []\n",
    "    edge_tensors = []\n",
    "    for v in neighbours:\n",
    "        if v < p:\n",
    "            edge_set.append((v,p))\n",
    "            edge_tensors.append(f'G_{v}_{p}')\n",
    "        else:\n",
    "            edge_set.append((p,v))\n",
    "            edge_tensors.append(f'G_{p}_{v}')\n",
    "    return edge_set\n",
    "\n",
    "# Get all bonds globally\n",
    "def get_all_bonds_global(n):\n",
    "    bonds = []\n",
    "    for j in range(n**2):\n",
    "        for p in next_to(j,n, T = BC):\n",
    "            bonds.append(bond_map(f'G_{j}_{p}'))\n",
    "        bonds = list(set(bonds))\n",
    "    return bonds\n",
    "\n",
    "# Get all local bonds\n",
    "def get_all_bonds(j,n):\n",
    "    bonds = []\n",
    "    for p in next_to(j,n, T = BC):\n",
    "        bonds.append(bond_map(f'G_{j}_{p}'))\n",
    "    bonds = list(set(bonds))\n",
    "    return bonds\n",
    "\n",
    "# Bond map G_j_i -> G_i_j where i < j\n",
    "def bond_map(bond):\n",
    "    # print(bond)\n",
    "    G,i,j = bond.split('_')\n",
    "    if int(i) < int(j):\n",
    "        return f'G_{int(i)}_{int(j)}'\n",
    "    else:\n",
    "        return f'G_{int(j)}_{int(i)}'\n",
    "\n",
    "# Decompose bonds\n",
    "def decompose_bond(bond):\n",
    "    \n",
    "    A = bond.split('_')\n",
    "    i = A[1]\n",
    "    j = A[2]\n",
    "    decomp = [f'G_{i}',f'G_{j}']\n",
    "    return decomp\n",
    "\n",
    "# Corner map G_i_j_k -> G_k_j_i wherer k < i\n",
    "def corner_map(bond):\n",
    "    G,i,j,k = bond.split('_')\n",
    "    if int(i) < int(k):\n",
    "        return f'G_{int(i)}_{int(j)}_{int(k)}'\n",
    "    else:\n",
    "        return f'G_{int(k)}_{int(j)}_{int(i)}'\n",
    "\n",
    "# Get corner tensors around a point, this will account for all the corners in a plus shape\n",
    "def get_corners(j,n):\n",
    "    neighbours = next_to(j,n, T = BC)\n",
    "    h_list = [p for p in neighbours if (p % n) == (j % n)]\n",
    "    v_list = [p for p in neighbours if (p % n) != (j % n)]\n",
    "    corners = [corner_map(f'G_{v}_{j}_{h}') for (v,h) in it.product(h_list,v_list)]\n",
    "    return corners\n",
    "\n",
    "# Get all rank 3 tensors surroundng a point.\n",
    "def get_all_3_tensors(j,n):\n",
    "    neighbours = next_to(j,n, T = BC)\n",
    "    _3_tensors = []\n",
    "    pairs = [(i,k) for i,k in it.combinations(neighbours,2)]\n",
    "    for (i,k) in pairs:\n",
    "        _3_tensors.append(f'G_{i}_{j}_{k}')\n",
    "    return _3_tensors\n",
    "\n",
    "# Split corners up into rank two tensors\n",
    "def decompose_corners(corner):\n",
    "    G,i,j,k = corner.split('_')\n",
    "    decomp = [bond_map(f'G_{i}_{j}'),bond_map(f'G_{j}_{k}')]\n",
    "    return decomp\n",
    "\n",
    "# Rank 4 tensor map\n",
    "def _4_tensor_map(tensor):\n",
    "    parts = tensor.split('_')[1:]\n",
    "    if int(parts[0]) > int(parts[-1]):\n",
    "        parts.reverse()\n",
    "    return(f'G_{parts[0]}_{parts[1]}_{parts[2]}_{parts[3]}')\n",
    "\n",
    "# Get all rank 4 tensors\n",
    "def get_4_tensors(j,n):\n",
    "    tensors = []\n",
    "    neighbours = next_to(j,n, T = BC)\n",
    "    d2_neighbours =[next_to(i,n) for i in neighbours]\n",
    "    for (a,b) in [(a,b) for a,b in it.combinations(neighbours,2)]:\n",
    "        for k in next_to(b,n):\n",
    "            tensors.append(_4_tensor_map(f'G_{a}_{j}_{b}_{k}'))\n",
    "    return list(set(tensors))\n",
    "\n",
    "# Decompose all rank 4 tensors\n",
    "def decompose_4_tensors(j,n):\n",
    "    G,i,j,k,l = corner.split('_')\n",
    "    decomp = [corner_map(f'G_{i}_{j}_{k}'),corner_map(f'G_{j}_{k}_{l}')]\n",
    "    return decomp\n",
    "\n",
    "def plot_solution(active_coords,active_edges,n):\n",
    "    n_ = n  # Size of the square lattice\n",
    "\n",
    "    # Create a 2D grid graph\n",
    "    G = nx.Graph()\n",
    "    for i in active_coords:\n",
    "        G.add_node(i)\n",
    "\n",
    "    for u, v in [(i, j) for i,j in active_edges]:\n",
    "        G.add_edge(u, v)\n",
    "\n",
    "    # Draw the nodes and edges of the graph\n",
    "    pos = {(i, j): (i, j) for i in range(n_) for j in range(n_)}\n",
    "    nx.draw(G, pos=pos, with_labels=True, node_size=10, edge_color='gray')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "def checking_function(N,L,sites,bonds,rank_three_tensors):\n",
    "    # Check there are the correct number of sites\n",
    "    if N == len(sites):\n",
    "        print('Correct number of sites:', N)\n",
    "    else:\n",
    "        print('Worng number of sites: ', len(sites))\n",
    "    # Check there are the correct number of bonds\n",
    "    if L == len(bonds):\n",
    "        print('Correct number of bonds:', L)\n",
    "    else:\n",
    "        print('Worng number of bonds: ', len(bonds))\n",
    "\n",
    "    # Check that there are 2 sites for every bond\n",
    "    for bond in bonds:\n",
    "        sites_in_bond = []\n",
    "        for site in sites:\n",
    "            if set(bond).issuperset(set(site)):\n",
    "                sites_in_bond.append(tuple(site))\n",
    "                # print(site,bond,len(set(tuple(sites_in_bond))))\n",
    "        if len(set(tuple(sites_in_bond))) != 2:\n",
    "            print('Bond : ' , bond, 'is not consistent.','The sites in this bond are: ',sites_in_bond)\n",
    "\n",
    "    # Check there is a bond on every site\n",
    "    for site in sites:\n",
    "        bonds_for_site = []\n",
    "        for bond in bonds:\n",
    "            if set(site).issubset(set(bond)):\n",
    "                bonds_for_site.append(tuple(bond))\n",
    "        if len(set(bonds_for_site)) != 1 and len(set(tuple(bonds_for_site))) != 2:\n",
    "            print('Site :',site, f'is part of {len(set(tuple(bonds_for_site)))} bonds')\n",
    "\n",
    "\n",
    "    # Check there are two bonds in every tensor\n",
    "    for t3 in rank_three_tensors:\n",
    "        for bond in bonds:\n",
    "            bond_in_tensor = []\n",
    "            if set(t3).issuperset(set(bond)):\n",
    "                bond_in_tensor.append(tuple(bond))\n",
    "            if len(set(bond_in_tensor)) > 2:\n",
    "                print('Tensor :', t3, 'is not consistent with bonds : ', bond)\n",
    "\n",
    "    for bond in bonds: \n",
    "        tensor_containing_bond = []\n",
    "        for t3 in rank_three_tensors:\n",
    "            if set(bond).issubset(t3):\n",
    "                tensor_containing_bond.append(tuple(t3))\n",
    "        if len(set(tensor_containing_bond)) != 1 and len(set(tensor_containing_bond)) != 2:\n",
    "            print('Bond :', bond, f'is part of {tensor_containing_bond} bonds')\n",
    "\n",
    "    \n",
    "    # Check that there are bonds for all rank 3 tensors\n",
    "    for t in rank_three_tensors:\n",
    "        t = corner_map(f'G_{t[0]}_{t[1]}_{t[2]}')\n",
    "        bond1, bond2 = decompose_corners(t)\n",
    "        bond1 = bond1.split('_')[1:]\n",
    "        bond2 = bond2.split('_')[1:]\n",
    "        if (bond1 not in bonds) or (bond2 not in bonds):\n",
    "            print(f'bond {bond1} or {bond2} are not contained within bonds but are in {t}' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_walk_bqm(n,N,L,Am,Ab,Asa,A2,A3,A4,L4,L6,BC):\n",
    "    #n is the size of the grid\n",
    "    #N is the number of active sites\n",
    "    #L is the number of bonds\n",
    "    #Am is the monomer strength\n",
    "    #Ab is the bond strength\n",
    "    #A2 is the rank 1-2 tensor consistency bias\n",
    "    #Asa is the self avoiding walk bias \n",
    "    #A3 is the rank 2-3 tensor consistency bias\n",
    "\n",
    "    X = [i for i in range(n**2)]\n",
    " \n",
    "    #Initialise BQM\n",
    "    bqm = dimod.BinaryQuadraticModel({}, {}, 0.0, dimod.BINARY)\n",
    "\n",
    "    #V_mon\n",
    "    V_mon = combinations([f'G_{i}' for i in X], N, strength = Am)\n",
    "    # print('V_mon : ', V_mon) \n",
    "    bqm.update(V_mon)\n",
    "    \n",
    "    #V_bond\n",
    "    bond_list = get_all_bonds_global(n)\n",
    "    V_bond = combinations(list(set(bond_list)), L, strength = Ab)\n",
    "    # print('V_bond : ', V_bond)\n",
    "    bqm.update(V_bond)\n",
    "\n",
    "    #V_SA\n",
    "    V_SA = dimod.BinaryQuadraticModel({}, {}, 0.0, dimod.BINARY)\n",
    "    for j in X:\n",
    "        _3_tensors = get_all_3_tensors(j,n)\n",
    "        if len(_3_tensors) != 1:\n",
    "            quadratic = [quad for quad in it.combinations(_3_tensors,2)]\n",
    "            for a,b in it.combinations(_3_tensors,2):\n",
    "                V_SA.add_quadratic(a,b,Asa)\n",
    "                # print([a for a in it.combinations(_3_tensors,2)])\n",
    "    # print('V_SA : ', V_SA)\n",
    "    bqm.update(V_SA)\n",
    "\n",
    "\n",
    "    #V_2 - consistancy relation between 2 sites and 1 bond\n",
    "    V_2 = dimod.BinaryQuadraticModel({}, {}, 0.0, dimod.BINARY)\n",
    "    for bond in get_all_bonds_global(n):\n",
    "        i,j = decompose_bond(bond)\n",
    "        V_2.add_linear(bond,A2)\n",
    "        V_2.add_quadratic(bond,i, - A2/2)\n",
    "        V_2.add_quadratic(bond,j, - A2/2)\n",
    "\n",
    "    # for i in X:\n",
    "    #     for j in next_to(i,n):\n",
    "    #         V_2.add_linear(bond_map(f'G_{i}_{j}'),A2)\n",
    "    #         V_2.add_quadratic(bond_map(f'G_{i}_{j}'),f'G_{i}', - A2)\n",
    "    #         # V_2.add_quadratic(bond_map(f'G_{i}_{j}'),f'G_{j}', - A2)\n",
    "    # # print('V_2 : ', V_2)\n",
    "    bqm.update(V_2)\n",
    "\n",
    "\n",
    "    # V_3 - consistancy relation between and walk of length 3 and the corresponding sites \n",
    "    V_3 = dimod.BinaryQuadraticModel({}, {}, 0.0, dimod.BINARY)\n",
    "    for j in X:\n",
    "        L = []\n",
    "        for _3_tensors in get_all_3_tensors(j,n):\n",
    "           binarys = decompose_corners(_3_tensors)\n",
    "           V_3.add_linear(_3_tensors,A3/math.factorial(3))\n",
    "           V_3.add_quadratic(binarys[0],binarys[1],A3/math.factorial(3))\n",
    "           V_3.add_quadratic(_3_tensors,binarys[0],-2*A3/math.factorial(3))    \n",
    "           V_3.add_quadratic(_3_tensors,binarys[1],-2*A3/math.factorial(3))    \n",
    "           L.append([_3_tensors,binarys])\n",
    "        #    print(j,_3_tensors,binarys)\n",
    "    # print('V_3 : ', V_3)\n",
    "    bqm.update(V_3)\n",
    "    return bqm\n",
    "\n",
    "# V_4 - consistancy relation between and walk of length 4 and the corresponding sites \n",
    "    V_4 = dimod.BinaryQuadraticModel({}, {}, 0.0, dimod.BINARY)\n",
    "    for j in X:\n",
    "        L = []\n",
    "        for _4_tensors in get_4_tensors(j,n):\n",
    "           binarys = decompose_4_tensors(_4_tensors)\n",
    "           V_4.add_linear(_4_tensors,A3/math.factorial(3))\n",
    "           V_4.add_quadratic(binarys[0],binarys[1],A4/math.factorial(3))\n",
    "           V_4.add_quadratic(_4_tensors,binarys[0],-2*A4/math.factorial(3))    \n",
    "           V_4.add_quadratic(_4_tensors,binarys[1],-2*A4/math.factorial(3))    \n",
    "           L.append([_4_tensors,binarys])\n",
    "        #    print(j,_4_tensors,binarys)\n",
    "    # print('V_4 : ', V_4)\n",
    "    bqm.update(V_4)\n",
    "    return bqm\n",
    "\n",
    "\n",
    "    # L_4 - suppressing 4-loops\n",
    "    L_4 = dimod.BinaryQuadraticModel({}, {}, 0.0, dimod.BINARY)\n",
    "    _3_tensors = []\n",
    "    for i in X:\n",
    "        _3_tensors += get_all_3_tensors(j,n)\n",
    "    _3_tensors = list(set(_3_tensors))\n",
    "    for tensor1, tensor2 in it.combinations(_3_tensors,2):\n",
    "        s_1 = int(tensor1.split('_')[1]) #manipulate the start if the first tensor\n",
    "        f_1 = int(tensor1.split('_')[-1]) #manipulate the end of the first tensor \n",
    "        s_2 = int(tensor2.split('_')[1]) #...\n",
    "        f_2 = int(tensor2.split('_')[-1]) #...\n",
    "        if s_1 == s_2 and f_1 == f_2 and tensor1 != tensor2:\n",
    "            L_4.add_quadratic(tensor1,tensor2,L4)\n",
    "    bqm.update(L_4)\n",
    "\n",
    "\n",
    "    # L_6 Supress higher order loops\n",
    "    L_6 = dimod.BinaryQuadraticModel({}, {}, 0.0, dimod.BINARY)\n",
    "    _4_tensors = []\n",
    "    for i in X:\n",
    "        _4_tensors + get_4_tensors(i)\n",
    "    for t1,t2 in it.combinations(_4_tensors,2):\n",
    "        if t1.split('_')[1] == t2.split('_')[1] and t1.split('_')[-1] == t2.split('_')[-1]:\n",
    "            L.add_quadratic(t1,t2,L6)\n",
    "    bqm.update(L_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 4,N = 15,L = 7,Am=1,Ab=2,Asa=30,A2=1 works very well\n",
    "BC = 'Default'\n",
    "# BC = 'Periodic'\n",
    "\n",
    "n = 6\n",
    "N = 20\n",
    "L = 18\n",
    "Am = 1\n",
    "Ab= 1\n",
    "Asa= 120\n",
    "A2= 2\n",
    "A3= 6\n",
    "\n",
    "A4= 0\n",
    "L4= 0 #24\n",
    "L6= 0\n",
    "                                    \n",
    "random_walk_bqm = get_random_walk_bqm(n,N,L,Am,Ab,Asa,A2,A3,A4,L4,L6,BC)\n",
    "\n",
    "# solution = KerberosSampler().sample(random_walk_bqm, num_reads = 10)\n",
    "\n",
    "# solution_dataframe = solution.to_pandas_dataframe()\n",
    "\n",
    "# all_solutions = []\n",
    "# all_energy_num = []\n",
    "# for i in range(solution_dataframe.shape[0]):\n",
    "#     all_solutions.append(solution_dataframe.iloc[0,:-2].to_dict())\n",
    "#     all_energy_num.append(solution_dataframe.iloc[0,-2:].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Hamiltonian(Ising_dict):\n",
    "    \"\"\"\n",
    "    Function in charge of generating the Hamiltonian of the statement.\n",
    "\n",
    "    Args:\n",
    "        h (float): magnetic field strength\n",
    "\n",
    "    Returns:\n",
    "        (qml.Hamiltonian): Hamiltonian of the statement associated to h\n",
    "    \"\"\"\n",
    "    obs = []\n",
    "    coeff = []\n",
    "\n",
    "    #Create linear terms\n",
    "    for linear in Ising_dict[0].keys():\n",
    "        obs.append(qml.PauliZ(linear))\n",
    "        coeff.append(Ising_dict[0][linear])\n",
    "\n",
    "    for i,j in list(Ising_dict[1].keys()):\n",
    "        obs.append(qml.PauliZ(i) @ qml.PauliZ(j))\n",
    "        coeff.append(Ising_dict[1][(i,j)])\n",
    "    \n",
    "    H = qml.Hamiltonian(coeff, obs)\n",
    "\n",
    "\n",
    "    return(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Hamiltonian: terms=3348, wires=['G_0', 'G_0_1', 'G_0_6', 'G_0_6_7', 'G_1', 'G_10', 'G_10_11', 'G_10_16', 'G_10_16_15', 'G_10_16_17', 'G_10_4_3', 'G_10_4_5', 'G_10_9_8', 'G_11', 'G_11_10_9', 'G_11_17', 'G_11_17_16', 'G_11_5_4', 'G_12', 'G_12_13', 'G_12_18', 'G_12_18_19', 'G_12_6_0', 'G_12_6_7', 'G_13', 'G_13_14', 'G_13_19', 'G_13_19_18', 'G_13_19_20', 'G_13_7_1', 'G_13_7_6', 'G_13_7_8', 'G_14', 'G_14_13_12', 'G_14_15', 'G_14_20', 'G_14_20_19', 'G_14_20_21', 'G_14_8_2', 'G_14_8_7', 'G_14_8_9', 'G_15', 'G_15_14_13', 'G_15_16', 'G_15_21', 'G_15_21_20', 'G_15_21_22', 'G_15_9_10', 'G_15_9_3', 'G_15_9_8', 'G_16', 'G_16_10_11', 'G_16_10_4', 'G_16_10_9', 'G_16_15_14', 'G_16_17', 'G_16_22', 'G_16_22_21', 'G_16_22_23', 'G_17', 'G_17_11_10', 'G_17_11_5', 'G_17_16_15', 'G_17_23', 'G_17_23_22', 'G_18', 'G_18_12_13', 'G_18_12_6', 'G_18_19', 'G_18_24', 'G_18_24_25', 'G_19', 'G_19_13_12', 'G_19_13_14', 'G_19_13_7', 'G_19_20', 'G_19_25', 'G_19_25_24', 'G_19_25_26', 'G_1_2', 'G_1_7', 'G_1_7_6', 'G_1_7_8', 'G_2', 'G_20', 'G_20_14_13', 'G_20_14_15', 'G_20_14_8', 'G_20_19_18', 'G_20_21', 'G_20_26', 'G_20_26_25', 'G_20_26_27', 'G_21', 'G_21_15_14', 'G_21_15_16', 'G_21_15_9', 'G_21_20_19', 'G_21_22', 'G_21_27', 'G_21_27_26', 'G_21_27_28', 'G_22', 'G_22_16_10', 'G_22_16_15', 'G_22_16_17', 'G_22_21_20', 'G_22_23', 'G_22_28', 'G_22_28_27', 'G_22_28_29', 'G_23', 'G_23_17_11', 'G_23_17_16', 'G_23_22_21', 'G_23_29', 'G_23_29_28', 'G_24', 'G_24_18_12', 'G_24_18_19', 'G_24_25', 'G_24_30', 'G_24_30_31', 'G_25', 'G_25_19_13', 'G_25_19_18', 'G_25_19_20', 'G_25_26', 'G_25_31', 'G_25_31_30', 'G_25_31_32', 'G_26', 'G_26_20_14', 'G_26_20_19', 'G_26_20_21', 'G_26_25_24', 'G_26_27', 'G_26_32', 'G_26_32_31', 'G_26_32_33', 'G_27', 'G_27_21_15', 'G_27_21_20', 'G_27_21_22', 'G_27_26_25', 'G_27_28', 'G_27_33', 'G_27_33_32', 'G_27_33_34', 'G_28', 'G_28_22_16', 'G_28_22_21', 'G_28_22_23', 'G_28_27_26', 'G_28_29', 'G_28_34', 'G_28_34_33', 'G_28_34_35', 'G_29', 'G_29_23_17', 'G_29_23_22', 'G_29_28_27', 'G_29_35', 'G_29_35_34', 'G_2_1_0', 'G_2_3', 'G_2_8', 'G_2_8_7', 'G_2_8_9', 'G_3', 'G_30', 'G_30_24_18', 'G_30_24_25', 'G_30_31', 'G_31', 'G_31_25_19', 'G_31_25_24', 'G_31_25_26', 'G_31_32', 'G_32', 'G_32_26_20', 'G_32_26_25', 'G_32_26_27', 'G_32_31_30', 'G_32_33', 'G_33', 'G_33_27_21', 'G_33_27_26', 'G_33_27_28', 'G_33_32_31', 'G_33_34', 'G_34', 'G_34_28_22', 'G_34_28_27', 'G_34_28_29', 'G_34_33_32', 'G_34_35', 'G_35', 'G_35_29_23', 'G_35_29_28', 'G_35_34_33', 'G_3_2_1', 'G_3_4', 'G_3_9', 'G_3_9_10', 'G_3_9_8', 'G_4', 'G_4_10', 'G_4_10_11', 'G_4_10_9', 'G_4_3_2', 'G_4_5', 'G_5', 'G_5_11', 'G_5_11_10', 'G_5_4_3', 'G_6', 'G_6_0_1', 'G_6_12', 'G_6_12_13', 'G_6_7', 'G_7', 'G_7_13', 'G_7_13_12', 'G_7_13_14', 'G_7_1_0', 'G_7_1_2', 'G_7_8', 'G_8', 'G_8_14', 'G_8_14_13', 'G_8_14_15', 'G_8_2_1', 'G_8_2_3', 'G_8_7_6', 'G_8_9', 'G_9', 'G_9_10', 'G_9_15', 'G_9_15_14', 'G_9_15_16', 'G_9_3_2', 'G_9_3_4', 'G_9_8_7']>\n"
     ]
    }
   ],
   "source": [
    "create_Hamiltonian(random_walk_bqm.to_ising())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(create_Hamiltonian(random_walk_bqm.to_ising()).wires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Maximum allowed dimension exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dev \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39;49mdevice(\u001b[39m\"\u001b[39;49m\u001b[39mdefault.qubit\u001b[39;49m\u001b[39m\"\u001b[39;49m, wires\u001b[39m=\u001b[39;49mcreate_Hamiltonian(random_walk_bqm\u001b[39m.\u001b[39;49mto_ising())\u001b[39m.\u001b[39;49mwires)\n\u001b[1;32m      3\u001b[0m \u001b[39m@qml\u001b[39m\u001b[39m.\u001b[39mqnode(dev)\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel\u001b[39m(params, H):\n\u001b[1;32m      5\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m    To implement VQE you need an ansatz for the candidate ground state!\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m    Define here the VQE ansatz in terms of some parameters (params) that\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m        (float): Expected value with respect to the Hamiltonian H\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Q_env/lib/python3.10/site-packages/pennylane/__init__.py:326\u001b[0m, in \u001b[0;36mdevice\u001b[0;34m(name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[39mraise\u001b[39;00m DeviceError(\n\u001b[1;32m    321\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m plugin requires PennyLane versions \u001b[39m\u001b[39m{\u001b[39;00mplugin_device_class\u001b[39m.\u001b[39mpennylane_requires\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhowever PennyLane version \u001b[39m\u001b[39m{\u001b[39;00m__version__\u001b[39m}\u001b[39;00m\u001b[39m is installed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m     )\n\u001b[1;32m    325\u001b[0m \u001b[39m# Construct the device\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m dev \u001b[39m=\u001b[39m plugin_device_class(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    328\u001b[0m \u001b[39m# Once the device is constructed, we set its custom expansion function if\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[39m# any custom decompositions were specified.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[39mif\u001b[39;00m custom_decomps \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Q_env/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:184\u001b[0m, in \u001b[0;36mDefaultQubit.__init__\u001b[0;34m(self, wires, r_dtype, c_dtype, shots, analytic)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_debugger \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m# Create the initial state. Internally, we store the\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m# state as an array of dimension [2]*wires.\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_basis_state(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    185\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_rotated_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\n\u001b[1;32m    187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_ops \u001b[39m=\u001b[39m {\n\u001b[1;32m    188\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPauliX\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_x,\n\u001b[1;32m    189\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPauliY\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mToffoli\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_toffoli,\n\u001b[1;32m    199\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/Q_env/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:676\u001b[0m, in \u001b[0;36mDefaultQubit._create_basis_state\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_basis_state\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m    665\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a computational basis state over all wires.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \n\u001b[1;32m    667\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[39m    Note: This function does not support broadcasted inputs yet.\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m     state \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros(\u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_wires, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mcomplex128)\n\u001b[1;32m    677\u001b[0m     state[index] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    678\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_asarray(state, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC_DTYPE)\n",
      "\u001b[0;31mValueError\u001b[0m: Maximum allowed dimension exceeded"
     ]
    }
   ],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=create_Hamiltonian(random_walk_bqm.to_ising()).wires)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def model(params, H):\n",
    "    \"\"\"\n",
    "    To implement VQE you need an ansatz for the candidate ground state!\n",
    "    Define here the VQE ansatz in terms of some parameters (params) that\n",
    "    create the candidate ground state. These parameters will\n",
    "    be optimized later.\n",
    "\n",
    "    Args:\n",
    "        params (numpy.array): parameters to be used in the variational circuit\n",
    "        H (qml.Hamiltonian): Hamiltonian used to calculate the expected value\n",
    "\n",
    "    Returns:\n",
    "        (float): Expected value with respect to the Hamiltonian H\n",
    "    \"\"\"\n",
    "\n",
    "   # Put your code here #\n",
    "    k = 0\n",
    "    for i in H.wires: \n",
    "        qml.RZ(params[k],i)\n",
    "        k+= 1\n",
    "        qml.RY(params[k],i)\n",
    "        k+= 1\n",
    "        \n",
    "    for i in H.wires: \n",
    "        if i != H.wires[0]:\n",
    "            qml.CNOT([H.wires[0],i])\n",
    "        \n",
    "        \n",
    "    for i in H.wires:\n",
    "        qml.RY(params[k],i)\n",
    "        k+=1\n",
    "        qml.RZ(params[k],i)\n",
    "        k+=1\n",
    "        \n",
    "    return qml.expval(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.74112454, requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_params = np.random.random(4*len(create_Hamiltonian(random_walk_bqm.to_ising()).wires))\n",
    "model(init_params,create_Hamiltonian(random_walk_bqm.to_ising()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Ising_dict):\n",
    "    \"\"\"\n",
    "    In this function you must design a subroutine that returns the\n",
    "    parameters that best approximate the ground state.\n",
    "\n",
    "    Args:\n",
    "        h (float): magnetic field strength\n",
    "\n",
    "    Returns:\n",
    "        (numpy.array): parameters that best approximate the ground state.\n",
    "    \"\"\"\n",
    "    \n",
    "    H = create_Hamiltonian(Ising_dict)\n",
    "    \n",
    "    \n",
    "    init_params = np.random.random(4*len(Ising_dict[0]))\n",
    " \n",
    "    def cost_fn(params):\n",
    "        return model(params, H)\n",
    "        \n",
    "    \n",
    "    opt = qml.GradientDescentOptimizer(stepsize=0.01)\n",
    "\n",
    "    params = init_params\n",
    "\n",
    "    gd_param_history = [params]\n",
    "    gd_cost_history = []\n",
    "    max_iterations = 10000\n",
    "    conv_tol = 1e-06\n",
    "\n",
    "\n",
    "    for n in range(max_iterations):\n",
    "\n",
    "        # Take step\n",
    "        params, prev_energy = opt.step_and_cost(cost_fn, params)\n",
    "        gd_param_history.append(params)\n",
    "        gd_cost_history.append(prev_energy)\n",
    "\n",
    "        energy = cost_fn(params)\n",
    "\n",
    "        # Calculate difference between new and old energies\n",
    "        conv = np.abs(energy - prev_energy)\n",
    "\n",
    "        # if n % 20 == 0:\n",
    "        #     print(\n",
    "        #         \"Iteration = {:},  Energy = {:.8f} Ha,  Convergence parameter = {\"\n",
    "        #         \":.8f} Ha\".format(n, energy, conv)\n",
    "        #     )\n",
    "\n",
    "        if conv <= conv_tol:\n",
    "            break\n",
    "\n",
    "#         print()\n",
    "#         print(\"Final value of the energy = {:.8f} Ha\".format(energy))\n",
    "#         print(\"Number of iterations = \", n)\n",
    "        \n",
    "    return params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.28963335e-01,  3.98626896e-11,  4.00815389e-01,\n",
       "        -2.11307118e-01,  7.97102886e-01,  1.47083143e+00,\n",
       "         2.38933029e-01,  2.51664603e-01,  9.53431987e-01,\n",
       "        -9.29439903e-02,  8.18579261e-01,  3.91165975e-01,\n",
       "         5.64203151e-01, -1.90999628e-01,  2.78642779e-01,\n",
       "         3.43030508e-01,  9.84202554e-01, -1.24925969e-01,\n",
       "         4.37461472e-02, -1.79724805e-02,  6.93092118e-01,\n",
       "         1.80400079e-01,  1.87842506e-01,  9.55894749e-02,\n",
       "         6.90660678e-02,  7.99056105e-01,  2.11310676e-01,\n",
       "         3.08451103e-01,  1.66656926e+00,  6.89389299e-01,\n",
       "        -2.51527047e-01,  8.81805410e-01,  9.30367210e-02,\n",
       "         4.29183909e-01, -3.86507285e-01,  7.12751267e-01,\n",
       "         1.90999632e-01,  6.96909085e-02,  3.83113253e-01,\n",
       "         4.95217051e-01,  1.24968366e-01,  5.18655198e-01,\n",
       "         1.80080042e-02,  2.45250709e-01, -1.80335376e-01,\n",
       "         5.77396178e-02, -9.55894743e-02,  7.34656617e-01], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = train(random_walk_bqm.to_ising())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=create_Hamiltonian(random_walk_bqm.to_ising()).wires, shots = 100)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(params, H):\n",
    "    \"\"\"\n",
    "    To implement VQE you need an ansatz for the candidate ground state!\n",
    "    Define here the VQE ansatz in terms of some parameters (params) that\n",
    "    create the candidate ground state. These parameters will\n",
    "    be optimized later.\n",
    "\n",
    "    Args:\n",
    "        params (numpy.array): parameters to be used in the variational circuit\n",
    "        H (qml.Hamiltonian): Hamiltonian used to calculate the expected value\n",
    "\n",
    "    Returns:\n",
    "        (float): Expected value with respect to the Hamiltonian H\n",
    "    \"\"\"\n",
    "\n",
    "   # Put your code here #\n",
    "    k = 0\n",
    "    for i in H.wires: \n",
    "        qml.RZ(params[k],i)\n",
    "        k+= 1\n",
    "        qml.RY(params[k],i)\n",
    "        k+= 1\n",
    "        \n",
    "    for i in H.wires: \n",
    "        if i != H.wires[0]:\n",
    "            qml.CNOT([H.wires[0],i])\n",
    "        \n",
    "        \n",
    "    for i in H.wires:\n",
    "        qml.RY(params[k],i)\n",
    "        k+=1\n",
    "        qml.RZ(params[k],i)\n",
    "        k+=1\n",
    "\n",
    "    return [qml.sample(qml.PauliZ(i)) for i in H.wires]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1,  1, ...,  1,  1,  1],\n",
       "        [ 1,  1,  1, ...,  1,  1,  1],\n",
       "        [-1, -1, -1, ..., -1, -1, -1],\n",
       "        ...,\n",
       "        [ 1,  1,  1, ...,  1,  1,  1],\n",
       "        [ 1,  1,  1, ...,  1,  1,  1],\n",
       "        [ 1,  1,  1, ...,  1,  1,  1]], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_state = circuit(params, create_Hamiltonian(random_walk_bqm.to_ising()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
